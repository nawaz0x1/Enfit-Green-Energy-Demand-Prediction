{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mean_absolute_error as MAE\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import r2_score as R2\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nimport sklearn\nimport lightgbm\nimport xgboost","metadata":{"_uuid":"25ebfc18-84e6-475e-a84f-40ae50f6baaf","_cell_guid":"4f123cbd-2143-4044-86cc-b6dc5cd6ad0f","collapsed":false,"_kg_hide-input":true,"papermill":{"duration":5.725246,"end_time":"2023-12-30T18:42:35.282395","exception":false,"start_time":"2023-12-30T18:42:29.557149","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:20:40.582365Z","iopub.execute_input":"2024-02-22T14:20:40.582799Z","iopub.status.idle":"2024-02-22T14:20:46.514747Z","shell.execute_reply.started":"2024-02-22T14:20:40.582766Z","shell.execute_reply":"2024-02-22T14:20:46.513378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classes","metadata":{"_uuid":"246ff586-83cd-4fb5-91da-04fe5a2471cf","_cell_guid":"fbd1d8f9-70d2-499f-a6ba-4fe2cafeb85c","papermill":{"duration":0.007775,"end_time":"2023-12-30T18:42:35.298223","exception":false,"start_time":"2023-12-30T18:42:35.290448","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"markdown","source":"### DataStorage","metadata":{"_uuid":"a93bbdf1-a8f6-4559-9266-ea07cd00d75f","_cell_guid":"66820c7a-87fc-41bd-956b-25bece10f9f1","papermill":{"duration":0.005184,"end_time":"2023-12-30T18:42:35.309513","exception":false,"start_time":"2023-12-30T18:42:35.304329","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"class DataStorage:\n    root = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n\n    data_cols = [\n        \"target\",\n        \"county\",\n        \"is_business\",\n        \"product_type\",\n        \"is_consumption\",\n        \"datetime\",\n        \"row_id\",\n    ]\n    client_cols = [\n        \"product_type\",\n        \"county\",\n        \"eic_count\",\n        \"installed_capacity\",\n        \"is_business\",\n        \"date\",\n    ]\n    gas_prices_cols = [\"forecast_date\", \"lowest_price_per_mwh\", \"highest_price_per_mwh\"]\n    electricity_prices_cols = [\"forecast_date\", \"euros_per_mwh\"]\n    forecast_weather_cols = [\n        \"latitude\",\n        \"longitude\",\n        \"hours_ahead\",\n        \"temperature\",\n        \"dewpoint\",\n        \"cloudcover_high\",\n        \"cloudcover_low\",\n        \"cloudcover_mid\",\n        \"cloudcover_total\",\n        \"10_metre_u_wind_component\",\n        \"10_metre_v_wind_component\",\n        \"forecast_datetime\",\n        \"direct_solar_radiation\",\n        \"surface_solar_radiation_downwards\",\n        \"snowfall\",\n        \"total_precipitation\",\n    ]\n    historical_weather_cols = [\n        \"datetime\",\n        \"temperature\",\n        \"dewpoint\",\n        \"rain\",\n        \"snowfall\",\n        \"surface_pressure\",\n        \"cloudcover_total\",\n        \"cloudcover_low\",\n        \"cloudcover_mid\",\n        \"cloudcover_high\",\n        \"windspeed_10m\",\n        \"winddirection_10m\",\n        \"shortwave_radiation\",\n        \"direct_solar_radiation\",\n        \"diffuse_radiation\",\n        \"latitude\",\n        \"longitude\",\n    ]\n    location_cols = [\"longitude\", \"latitude\", \"county\"]\n    target_cols = [\n        \"target\",\n        \"county\",\n        \"is_business\",\n        \"product_type\",\n        \"is_consumption\",\n        \"datetime\",\n    ]\n\n    def __init__(self):\n        self.df_data = pl.read_csv(\n            os.path.join(self.root, \"train.csv\"),\n            columns=self.data_cols,\n            try_parse_dates=True,\n        )\n        self.df_client = pl.read_csv(\n            os.path.join(self.root, \"client.csv\"),\n            columns=self.client_cols,\n            try_parse_dates=True,\n        )\n        self.df_gas_prices = pl.read_csv(\n            os.path.join(self.root, \"gas_prices.csv\"),\n            columns=self.gas_prices_cols,\n            try_parse_dates=True,\n        )\n        self.df_electricity_prices = pl.read_csv(\n            os.path.join(self.root, \"electricity_prices.csv\"),\n            columns=self.electricity_prices_cols,\n            try_parse_dates=True,\n        )\n        self.df_forecast_weather = pl.read_csv(\n            os.path.join(self.root, \"forecast_weather.csv\"),\n            columns=self.forecast_weather_cols,\n            try_parse_dates=True,\n        )\n        self.df_historical_weather = pl.read_csv(\n            os.path.join(self.root, \"historical_weather.csv\"),\n            columns=self.historical_weather_cols,\n            try_parse_dates=True,\n        )\n        self.df_weather_station_to_county_mapping = pl.read_csv(\n            os.path.join(self.root, \"weather_station_to_county_mapping.csv\"),\n            columns=self.location_cols,\n            try_parse_dates=True,\n        )\n        self.df_data = self.df_data.filter(\n            pl.col(\"datetime\") >= pd.to_datetime(\"2022-01-01\")\n        )\n        self.df_target = self.df_data.select(self.target_cols)\n\n        self.schema_data = self.df_data.schema\n        self.schema_client = self.df_client.schema\n        self.schema_gas_prices = self.df_gas_prices.schema\n        self.schema_electricity_prices = self.df_electricity_prices.schema\n        self.schema_forecast_weather = self.df_forecast_weather.schema\n        self.schema_historical_weather = self.df_historical_weather.schema\n        self.schema_target = self.df_target.schema\n\n        self.df_weather_station_to_county_mapping = (\n            self.df_weather_station_to_county_mapping.with_columns(\n                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            )\n        )\n\n    def update_with_new_data(\n        self,\n        df_new_client,\n        df_new_gas_prices,\n        df_new_electricity_prices,\n        df_new_forecast_weather,\n        df_new_historical_weather,\n        df_new_target,\n    ):\n        df_new_client = pl.from_pandas(\n            df_new_client[self.client_cols], schema_overrides=self.schema_client\n        )\n        df_new_gas_prices = pl.from_pandas(\n            df_new_gas_prices[self.gas_prices_cols],\n            schema_overrides=self.schema_gas_prices,\n        )\n        df_new_electricity_prices = pl.from_pandas(\n            df_new_electricity_prices[self.electricity_prices_cols],\n            schema_overrides=self.schema_electricity_prices,\n        )\n        df_new_forecast_weather = pl.from_pandas(\n            df_new_forecast_weather[self.forecast_weather_cols],\n            schema_overrides=self.schema_forecast_weather,\n        )\n        df_new_historical_weather = pl.from_pandas(\n            df_new_historical_weather[self.historical_weather_cols],\n            schema_overrides=self.schema_historical_weather,\n        )\n        df_new_target = pl.from_pandas(\n            df_new_target[self.target_cols], schema_overrides=self.schema_target\n        )\n\n        self.df_client = pl.concat([self.df_client, df_new_client]).unique(\n            [\"date\", \"county\", \"is_business\", \"product_type\"]\n        )\n        self.df_gas_prices = pl.concat([self.df_gas_prices, df_new_gas_prices]).unique(\n            [\"forecast_date\"]\n        )\n        self.df_electricity_prices = pl.concat(\n            [self.df_electricity_prices, df_new_electricity_prices]\n        ).unique([\"forecast_date\"])\n        self.df_forecast_weather = pl.concat(\n            [self.df_forecast_weather, df_new_forecast_weather]\n        ).unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n        self.df_historical_weather = pl.concat(\n            [self.df_historical_weather, df_new_historical_weather]\n        ).unique([\"datetime\", \"latitude\", \"longitude\"])\n        self.df_target = pl.concat([self.df_target, df_new_target]).unique(\n            [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n        )\n\n    def preprocess_test(self, df_test):\n        df_test = df_test.rename(columns={\"prediction_datetime\": \"datetime\"})\n        df_test = pl.from_pandas(\n            df_test[self.data_cols[1:]], schema_overrides=self.schema_data\n        )\n        return df_test","metadata":{"_uuid":"0c36af8c-d2f8-4e12-84f0-192748e02859","_cell_guid":"0388b23e-25ff-4112-b536-0daa42b95cf3","collapsed":false,"papermill":{"duration":0.041376,"end_time":"2023-12-30T18:42:35.356305","exception":false,"start_time":"2023-12-30T18:42:35.314929","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:20:46.517884Z","iopub.execute_input":"2024-02-22T14:20:46.518426Z","iopub.status.idle":"2024-02-22T14:20:46.557640Z","shell.execute_reply.started":"2024-02-22T14:20:46.518378Z","shell.execute_reply":"2024-02-22T14:20:46.556299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### FeaturesGenerator","metadata":{"_uuid":"ae5e828c-1c20-49a3-881b-a69af2ead20f","_cell_guid":"7fc1d72c-5f57-4249-b88c-32b3dec2ee02","papermill":{"duration":0.005142,"end_time":"2023-12-30T18:42:35.366988","exception":false,"start_time":"2023-12-30T18:42:35.361846","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"class FeaturesGenerator:\n    def __init__(self, data_storage):\n        self.data_storage = data_storage\n\n    def _add_general_features(self, df_features):\n        df_features = (\n            df_features.with_columns(\n                pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n                pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n                pl.col(\"datetime\").dt.day().alias(\"day\"),\n                pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n                pl.col(\"datetime\").dt.month().alias(\"month\"),\n                pl.col(\"datetime\").dt.year().alias(\"year\"),\n            )\n            .with_columns(\n                pl.concat_str(\n                    \"county\",\n                    \"is_business\",\n                    \"product_type\",\n                    \"is_consumption\",\n                    separator=\"_\",\n                ).alias(\"segment\"),\n            )\n            .with_columns(\n                (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n                (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n                (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n                (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n            )\n        )\n        return df_features\n\n    def _add_client_features(self, df_features):\n        df_client = self.data_storage.df_client\n\n        df_features = df_features.join(\n            df_client.with_columns(\n                (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n            ),\n            on=[\"county\", \"is_business\", \"product_type\", \"date\"],\n            how=\"left\",\n        )\n        return df_features\n\n    def _add_forecast_weather_features(self, df_features):\n        df_forecast_weather = self.data_storage.df_forecast_weather\n        df_weather_station_to_county_mapping = (\n            self.data_storage.df_weather_station_to_county_mapping\n        )\n\n        df_forecast_weather = (\n            df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"})\n            .filter((pl.col(\"hours_ahead\") >= 22) & pl.col(\"hours_ahead\") <= 45)\n            .drop(\"hours_ahead\")\n            .with_columns(\n                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            )\n            .join(\n                df_weather_station_to_county_mapping,\n                how=\"left\",\n                on=[\"longitude\", \"latitude\"],\n            )\n            .drop(\"longitude\", \"latitude\")\n        )\n\n        df_forecast_weather_date = (\n            df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n        )\n\n        df_forecast_weather_local = (\n            df_forecast_weather.filter(pl.col(\"county\").is_not_null())\n            .group_by(\"county\", \"datetime\")\n            .mean()\n        )\n\n        for hours_lag in [0, 7 * 24]:\n            df_features = df_features.join(\n                df_forecast_weather_date.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=\"datetime\",\n                how=\"left\",\n                suffix=f\"_forecast_{hours_lag}h\",\n            )\n            df_features = df_features.join(\n                df_forecast_weather_local.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=[\"county\", \"datetime\"],\n                how=\"left\",\n                suffix=f\"_forecast_local_{hours_lag}h\",\n            )\n\n        return df_features\n\n    def _add_historical_weather_features(self, df_features):\n        df_historical_weather = self.data_storage.df_historical_weather\n        df_weather_station_to_county_mapping = (\n            self.data_storage.df_weather_station_to_county_mapping\n        )\n\n        df_historical_weather = (\n            df_historical_weather.with_columns(\n                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            )\n            .join(\n                df_weather_station_to_county_mapping,\n                how=\"left\",\n                on=[\"longitude\", \"latitude\"],\n            )\n            .drop(\"longitude\", \"latitude\")\n        )\n\n        df_historical_weather_date = (\n            df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n        )\n\n        df_historical_weather_local = (\n            df_historical_weather.filter(pl.col(\"county\").is_not_null())\n            .group_by(\"county\", \"datetime\")\n            .mean()\n        )\n\n        for hours_lag in [2 * 24, 7 * 24]:\n            df_features = df_features.join(\n                df_historical_weather_date.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=\"datetime\",\n                how=\"left\",\n                suffix=f\"_historical_{hours_lag}h\",\n            )\n            df_features = df_features.join(\n                df_historical_weather_local.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ),\n                on=[\"county\", \"datetime\"],\n                how=\"left\",\n                suffix=f\"_historical_local_{hours_lag}h\",\n            )\n\n        for hours_lag in [1 * 24]:\n            df_features = df_features.join(\n                df_historical_weather_date.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag),\n                    pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n                )\n                .filter(pl.col(\"hour\") <= 10)\n                .drop(\"hour\"),\n                on=\"datetime\",\n                how=\"left\",\n                suffix=f\"_historical_{hours_lag}h\",\n            )\n\n        return df_features\n\n    def _add_target_features(self, df_features):\n        df_target = self.data_storage.df_target\n\n        df_target_all_type_sum = (\n            df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"])\n            .sum()\n            .drop(\"product_type\")\n        )\n\n        df_target_all_county_type_sum = (\n            df_target.group_by([\"datetime\", \"is_business\", \"is_consumption\"])\n            .sum()\n            .drop(\"product_type\", \"county\")\n        )\n\n        for hours_lag in [\n            2 * 24,\n            3 * 24,\n            4 * 24,\n            5 * 24,\n            6 * 24,\n            7 * 24,\n            8 * 24,\n            9 * 24,\n            10 * 24,\n            11 * 24,\n            12 * 24,\n            13 * 24,\n            14 * 24,\n        ]:\n            df_features = df_features.join(\n                df_target.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ).rename({\"target\": f\"target_{hours_lag}h\"}),\n                on=[\n                    \"county\",\n                    \"is_business\",\n                    \"product_type\",\n                    \"is_consumption\",\n                    \"datetime\",\n                ],\n                how=\"left\",\n            )\n\n        for hours_lag in [2 * 24, 3 * 24, 7 * 24, 14 * 24]:\n            df_features = df_features.join(\n                df_target_all_type_sum.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ).rename({\"target\": f\"target_all_type_sum_{hours_lag}h\"}),\n                on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"],\n                how=\"left\",\n            )\n\n            df_features = df_features.join(\n                df_target_all_county_type_sum.with_columns(\n                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n                ).rename({\"target\": f\"target_all_county_type_sum_{hours_lag}h\"}),\n                on=[\"is_business\", \"is_consumption\", \"datetime\"],\n                how=\"left\",\n                suffix=f\"_all_county_type_sum_{hours_lag}h\",\n            )\n\n        cols_for_stats = [\n            f\"target_{hours_lag}h\" for hours_lag in [2 * 24, 3 * 24, 4 * 24, 5 * 24]\n        ]\n        df_features = df_features.with_columns(\n            df_features.select(cols_for_stats).mean(axis=1).alias(f\"target_mean\"),\n            df_features.select(cols_for_stats)\n            .transpose()\n            .std()\n            .transpose()\n            .to_series()\n            .alias(f\"target_std\"),\n        )\n\n        for target_prefix, lag_nominator, lag_denomonator in [\n            (\"target\", 24 * 7, 24 * 14),\n            (\"target\", 24 * 2, 24 * 9),\n            (\"target\", 24 * 3, 24 * 10),\n            (\"target\", 24 * 2, 24 * 3),\n            (\"target_all_type_sum\", 24 * 2, 24 * 3),\n            (\"target_all_type_sum\", 24 * 7, 24 * 14),\n            (\"target_all_county_type_sum\", 24 * 2, 24 * 3),\n            (\"target_all_county_type_sum\", 24 * 7, 24 * 14),\n        ]:\n            df_features = df_features.with_columns(\n                (\n                    pl.col(f\"{target_prefix}_{lag_nominator}h\")\n                    / (pl.col(f\"{target_prefix}_{lag_denomonator}h\") + 1e-3)\n                ).alias(f\"{target_prefix}_ratio_{lag_nominator}_{lag_denomonator}\")\n            )\n\n        return df_features\n\n    def _reduce_memory_usage(self, df_features):\n        df_features = df_features.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n        return df_features\n\n    def _drop_columns(self, df_features):\n        df_features = df_features.drop(\n            \"date\", \"datetime\", \"hour\", \"dayofyear\"\n        )\n        return df_features\n\n    def _to_pandas(self, df_features, y):\n        cat_cols = [\n            \"county\",\n            \"is_business\",\n            \"product_type\",\n            \"is_consumption\",\n            \"segment\",\n        ]\n\n        if y is not None:\n            df_features = pd.concat([df_features.to_pandas(), y.to_pandas()], axis=1)\n        else:\n            df_features = df_features.to_pandas()\n\n        df_features = df_features.set_index(\"row_id\")\n                \n        df_features[cat_cols] = df_features[cat_cols].astype(\"category\")\n\n        return df_features\n\n    def generate_features(self, df_prediction_items):\n        if \"target\" in df_prediction_items.columns:\n            df_prediction_items, y = (\n                df_prediction_items.drop(\"target\"),\n                df_prediction_items.select(\"target\"),\n            )\n        else:\n            y = None\n\n        df_features = df_prediction_items.with_columns(\n            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n        )\n\n        for add_features in [\n            self._add_general_features,\n            self._add_client_features,\n            self._add_forecast_weather_features,\n            self._add_historical_weather_features,\n            self._add_target_features,\n            self._reduce_memory_usage,\n            self._drop_columns,\n        ]:\n            df_features = add_features(df_features)\n\n        df_features = self._to_pandas(df_features, y)\n\n        return df_features","metadata":{"_uuid":"b612ad48-9dee-4619-a3e5-219ca53aaa58","_cell_guid":"a8cbd0c1-0936-45e1-a83b-ca1b4f31e420","collapsed":false,"papermill":{"duration":0.054193,"end_time":"2023-12-30T18:42:35.426449","exception":false,"start_time":"2023-12-30T18:42:35.372256","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:20:46.559849Z","iopub.execute_input":"2024-02-22T14:20:46.560305Z","iopub.status.idle":"2024-02-22T14:20:46.618378Z","shell.execute_reply.started":"2024-02-22T14:20:46.560242Z","shell.execute_reply":"2024-02-22T14:20:46.617110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialisation","metadata":{"_uuid":"339a9a5d-284d-4739-8236-3b3965e3e117","_cell_guid":"7c8bf5e0-e849-4aae-93be-49be558e7858","papermill":{"duration":0.00722,"end_time":"2023-12-30T18:42:35.482223","exception":false,"start_time":"2023-12-30T18:42:35.475003","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"data_storage = DataStorage()\nfeatures_generator = FeaturesGenerator(data_storage=data_storage)","metadata":{"_uuid":"e06a1271-3a90-4852-bcdc-48b79f64ca3e","_cell_guid":"0fe22845-3500-42ef-abc4-cd5648a236d3","collapsed":false,"papermill":{"duration":5.063588,"end_time":"2023-12-30T18:42:40.551908","exception":false,"start_time":"2023-12-30T18:42:35.48832","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:20:46.621599Z","iopub.execute_input":"2024-02-22T14:20:46.622435Z","iopub.status.idle":"2024-02-22T14:20:52.218200Z","shell.execute_reply.started":"2024-02-22T14:20:46.622390Z","shell.execute_reply":"2024-02-22T14:20:52.217094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Generation","metadata":{"_uuid":"14f0039b-ef0a-4157-9d67-64e3da3ec7d3","_cell_guid":"23466843-e86d-4723-aac9-28199ab373a4","papermill":{"duration":0.0057,"end_time":"2023-12-30T18:42:40.563352","exception":false,"start_time":"2023-12-30T18:42:40.557652","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"df_train_features = features_generator.generate_features(data_storage.df_data)\ndf_train_features = df_train_features.dropna()","metadata":{"_uuid":"db9a6860-dc8a-4bd9-86ab-154bdb5b6ebf","_cell_guid":"73174d45-de06-4f68-b554-734a549bb8f3","collapsed":false,"papermill":{"duration":16.131879,"end_time":"2023-12-30T18:42:56.700433","exception":false,"start_time":"2023-12-30T18:42:40.568554","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:20:52.221781Z","iopub.execute_input":"2024-02-22T14:20:52.222173Z","iopub.status.idle":"2024-02-22T14:21:29.524370Z","shell.execute_reply.started":"2024-02-22T14:20:52.222143Z","shell.execute_reply":"2024-02-22T14:21:29.523155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import holidays\nimport datetime\n\nestonian_holidays = holidays.country_holidays('EE', years=range(2021, 2026))\nestonian_holidays = list(estonian_holidays.keys())\n\ndef add_holidays_as_binary_features(df):\n    df['country_holiday'] = df.apply(lambda row: (datetime.date(row['year'], row['month'], row['day']) in estonian_holidays) * 1, axis=1)\n    \n    return df\n\ndf_train_features = add_holidays_as_binary_features(df_train_features)","metadata":{"_uuid":"ffebd1f5-fcff-412f-b246-8280242218ed","_cell_guid":"8f6bba53-10a7-4228-be62-4bfd249de482","papermill":{"duration":54.848951,"end_time":"2023-12-30T18:43:51.555063","exception":false,"start_time":"2023-12-30T18:42:56.706112","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-22T14:21:29.526518Z","iopub.execute_input":"2024-02-22T14:21:29.526996Z","iopub.status.idle":"2024-02-22T14:21:59.411797Z","shell.execute_reply.started":"2024-02-22T14:21:29.526955Z","shell.execute_reply":"2024-02-22T14:21:59.410580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Demand Prediction for Consumers","metadata":{"_uuid":"7bd35410-e7a2-480a-9e0a-b1232a6ac70d","_cell_guid":"84c02191-0616-4b6a-952f-5712a3980a6c","trusted":true}},{"cell_type":"code","source":"df_train_features = df_train_features[df_train_features['is_consumption'] == 1]\ndf_train_features.pop('is_consumption')\ntarget = df_train_features.pop('target')","metadata":{"_uuid":"41607698-bfc1-4e3e-bb0e-cbb7dc9a4c8c","_cell_guid":"19a1e7dd-4e5b-4a53-ab01-19c93966031b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:21:59.413492Z","iopub.execute_input":"2024-02-22T14:21:59.413928Z","iopub.status.idle":"2024-02-22T14:21:59.591902Z","shell.execute_reply.started":"2024-02-22T14:21:59.413888Z","shell.execute_reply":"2024-02-22T14:21:59.590581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train_features[\n[ 'target_168h',\n  'target_336h',\n  'target_all_type_sum_168h',\n  'target_mean',\n  'target_144h',\n  'target_all_type_sum_336h',\n  'target_48h',\n  'target_std',\n  'direct_solar_radiation_forecast_local_0h',\n  'weekday' ]\n]\ny = target","metadata":{"_uuid":"ec53df24-f0f5-4af7-adbf-08b12ee49329","_cell_guid":"74a113fd-dfea-4f26-859b-819ac98b06e8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:21:59.593803Z","iopub.execute_input":"2024-02-22T14:21:59.594157Z","iopub.status.idle":"2024-02-22T14:21:59.604482Z","shell.execute_reply.started":"2024-02-22T14:21:59.594126Z","shell.execute_reply":"2024-02-22T14:21:59.603400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Benchmarking Different Models","metadata":{"_uuid":"5c8600c6-2dbe-4292-b350-a3c25014a5b3","_cell_guid":"f1db93ad-ffcc-4633-bb0c-8be62d04467d","trusted":true}},{"cell_type":"code","source":"# X, y = X[:1000], y[:1000]\nresults = []","metadata":{"_uuid":"2cc1a361-65cd-44b9-8e0a-febc262599d5","_cell_guid":"35add4d4-8de7-49f7-b044-7a81af795d03","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:21:59.621409Z","iopub.execute_input":"2024-02-22T14:21:59.621752Z","iopub.status.idle":"2024-02-22T14:21:59.629888Z","shell.execute_reply.started":"2024-02-22T14:21:59.621725Z","shell.execute_reply":"2024-02-22T14:21:59.628733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\n\ntscv = TimeSeriesSplit(n_splits = 5)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T14:21:59.631432Z","iopub.execute_input":"2024-02-22T14:21:59.631860Z","iopub.status.idle":"2024-02-22T14:21:59.642094Z","shell.execute_reply.started":"2024-02-22T14:21:59.631820Z","shell.execute_reply":"2024-02-22T14:21:59.640892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Regressor","metadata":{"_uuid":"bcfa3b94-96ff-4f6d-b5d6-0b9cfdf17946","_cell_guid":"c69225e0-843a-4f4d-a8cf-f5247febbbe9","trusted":true}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n    \n    decisionTreeRegressor = DecisionTreeRegressor(random_state = 42)\n    decisionTreeRegressor.fit(X_train, y_train)\n    y_pred = decisionTreeRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n        \nresults.append([\"DecisionTreeRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"8bf82c97-3316-4a86-a8bf-f0a4e8928b51","_cell_guid":"5d0849a3-13ab-45bc-90f7-b2d381e36b8e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:21:59.643944Z","iopub.execute_input":"2024-02-22T14:21:59.644416Z","iopub.status.idle":"2024-02-22T14:22:24.581833Z","shell.execute_reply.started":"2024-02-22T14:21:59.644374Z","shell.execute_reply":"2024-02-22T14:22:24.580623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Regressor","metadata":{"_uuid":"b5fdfd48-c376-4b70-a2aa-7b6f41e25505","_cell_guid":"c04bad09-6d04-4213-a582-ea7148065e3a","trusted":true}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    randomForestRegressor = RandomForestRegressor(random_state = 42, n_jobs = -1)\n    randomForestRegressor.fit(X_train, y_train)\n    y_pred = randomForestRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"RandomForestRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"59200fe5-3b14-4dcc-b8cb-094d2711a3f5","_cell_guid":"082902ed-2315-44c3-b456-e7b8f1ed6284","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-22T14:22:24.585713Z","iopub.execute_input":"2024-02-22T14:22:24.586162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting Regressor","metadata":{"_uuid":"4b6c0a41-4df5-452d-bc56-90d3e961877c","_cell_guid":"6a1aabe5-c909-4ceb-b4f1-d259216eb5ca","trusted":true}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    gradientBoostingRegressor = GradientBoostingRegressor(random_state = 42)\n    gradientBoostingRegressor.fit(X_train, y_train)\n    y_pred = gradientBoostingRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"GradientBoostingRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"9ba3b847-2fe1-4c0d-9522-0d4e1460f41b","_cell_guid":"3b0186a9-78e9-4bf0-b62f-530e4ed3a1e1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hist Gradient Boosting Regressor","metadata":{"_uuid":"0e0a9fce-dd1f-4570-958a-13d52321b244","_cell_guid":"0ee815f9-f70d-4cb0-a132-a423e05ee67b","trusted":true}},{"cell_type":"code","source":"from sklearn.ensemble import HistGradientBoostingRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    histGradientBoostingRegressor = HistGradientBoostingRegressor(random_state = 42)\n    histGradientBoostingRegressor.fit(X_train, y_train)\n    y_pred = histGradientBoostingRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"HistGradientBoostingRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"68a31631-5198-424c-a6af-39886f4c036c","_cell_guid":"631c063a-61de-4377-81de-9c072f2791e8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGB Regressor","metadata":{"_uuid":"18162f41-306b-4706-93d3-77f585715c00","_cell_guid":"9d5d2318-73e3-4d5d-b0be-b468eddc5bf4","trusted":true}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    xgbRegressor = XGBRegressor(random_state = 42, n_jobs = -1, enable_categorical = True)\n    xgbRegressor.fit(X_train, y_train)\n    y_pred = xgbRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"XGBRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"f2ff219f-b71b-4f0d-865e-df2b061fe987","_cell_guid":"7aa3c92f-f06f-4c3a-ad2d-f40c074f0652","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM Regressor","metadata":{"_uuid":"6672c649-c94d-44f8-9a47-9e2354288486","_cell_guid":"77f75e33-443e-45e9-8337-ad348d4586c8","trusted":true}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    lgbmRegressor = LGBMRegressor(random_state = 42, verbosity = -1, n_jobs = -1)\n    lgbmRegressor.fit(X_train, y_train)\n    y_pred = lgbmRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"LGBMRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"b4f09875-62a8-445f-8e5f-22a071c09127","_cell_guid":"5d13f2a7-e955-440a-8acf-812cec57461d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuned LGBM Regressor","metadata":{}},{"cell_type":"code","source":"maes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    tuned_lgbmRegressor = LGBMRegressor(random_state = 42,\n                                        num_leaves = 10,\n                                        min_data_in_leaf = 239,\n                                        learning_rate = 0.07536806217758459,\n                                        num_iterations = 896,\n                                        lambda_l1 = 0.007940261601555604,\n                                        lambda_l2 = 1.5359206369861043,\n                                        verbosity = -1,\n                                        n_jobs = -1)\n    tuned_lgbmRegressor.fit(X_train, y_train)\n    y_pred = tuned_lgbmRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"LGBMRegressor (Tuned)\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CatBoost Regressor","metadata":{"_uuid":"c42894b8-4b51-47d7-bee1-670177e428ed","_cell_guid":"c0929e63-298d-40c2-8982-783adaa1c16e","_kg_hide-output":true,"trusted":true}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    catBoostRegressor = CatBoostRegressor(random_state = 42, verbose = False)\n    catBoostRegressor.fit(X_train, y_train)\n    y_pred = catBoostRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"CatBoostRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"6792f54a-4d95-49c2-9423-f1a7a57be543","_cell_guid":"e2b780c1-6e14-46a9-bc1d-584f10c89cba","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-hot Encoding","metadata":{"_uuid":"2d6955f1-0256-4279-afbc-3ddd5c33a432","_cell_guid":"4593cec2-4324-4aea-a669-993c10975cd2","trusted":true}},{"cell_type":"code","source":"# cats = ['county', 'is_business', 'product_type', 'segment']\n# X_train = pd.get_dummies(X_train, columns=cats, drop_first=True)\n# X_test = pd.get_dummies(X_test, columns=cats, drop_first=True)","metadata":{"_uuid":"79147fe3-7e5d-44da-8b0b-41da3b9889df","_cell_guid":"2836bffe-356d-40be-963a-390d61904f34","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression","metadata":{"_uuid":"edfd6ff5-1786-424b-9768-17b2f9d85434","_cell_guid":"fb901397-b038-4e88-9ac0-b1156ed5ac83","trusted":true}},{"cell_type":"code","source":"# from sklearn.linear_model import LinearRegression\n\n# linearRegression = Pipeline([\n#     ('StandardScaler', StandardScaler()),\n#     ('LinearRegression', LinearRegression())\n# ])\n\n# linearRegression.fit(X_train, y_train)\n# y_pred = linearRegression.predict(X_test)\n\n# mae = MAE(y_test, y_pred)\n# mse = MSE(y_test, y_pred)\n# rmse = np.sqrt(mse)\n# r2 = R2(y_test, y_pred)\n\n# results.append([\"LinearRegression\", mae, mse, rmse, r2])\n# print(results[-1])","metadata":{"_uuid":"6a0523c7-7396-460d-a13e-9aeb7a43c7a0","_cell_guid":"069ffab3-dbf6-4e4a-bc2a-3c4bd09ef8ef","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Elastic Net","metadata":{"_uuid":"451f2515-4ea0-47ad-8b24-aa637e26f7a2","_cell_guid":"ad0c6dd1-1395-4354-a63f-6269ab86864f","trusted":true}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n    \n    elasticNet = Pipeline([\n        ('StandardScaler', StandardScaler()),\n        ('ElasticNet', ElasticNet(random_state = 42))\n    ])\n\n    elasticNet.fit(X_train, y_train)\n    y_pred = elasticNet.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"ElasticNet\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"e864bd8b-39bd-4163-b543-e932f3fb255c","_cell_guid":"41875509-453a-4180-b0fe-75460032042c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lasso","metadata":{"_uuid":"34d2b68f-d53b-4d29-aedd-e556044c6c37","_cell_guid":"8fb9e0a6-69ab-4e71-88a4-95ca87162221","trusted":true}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    lasso = Pipeline([\n        ('StandardScaler', StandardScaler()),\n        ('Lasso', Lasso(random_state = 42))\n    ])\n\n    lasso.fit(X_train, y_train)\n    y_pred = lasso.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"Lasso\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"5ddaea7c-f5ab-4777-8828-666c9534912b","_cell_guid":"ff264eff-25fb-4bdf-a6c9-d6fc0c5e531f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ridge","metadata":{"_uuid":"8d7a7a09-a1b9-4e90-ba65-577eabd729b4","_cell_guid":"b375b9a3-da6c-4f57-ba86-baad0d695b42","trusted":true}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    ridge = Pipeline([\n        ('StandardScaler', StandardScaler()),\n        ('Ridge', Ridge())\n    ])\n\n    ridge.fit(X_train, y_train)\n    y_pred = ridge.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"Ridge\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"536e0d0d-bb31-4b76-bd74-7bad973100db","_cell_guid":"ad68a61b-e297-4a00-9a3e-0a8c998461fd","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LinearSVR","metadata":{"_uuid":"4d7229f6-e732-4133-89e4-5049f61d65a6","_cell_guid":"cdb72e0c-12e3-4c68-b2d8-9a724c7a40dd","trusted":true}},{"cell_type":"code","source":"from sklearn.svm import LinearSVR\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    linearSVR = Pipeline([\n        ('StandardScaler', StandardScaler()),\n        ('LinearSVR', LinearSVR())\n    ])\n\n    linearSVR.fit(X_train, y_train)\n    y_pred = linearSVR.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n\nresults.append([\"LinearSVR\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"8660ba87-0636-4bb4-85e0-49479b014b32","_cell_guid":"996f5a06-08ac-496c-b968-14b3dab4acce","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVR","metadata":{"_uuid":"6d23ea30-1da0-4dc5-81a5-d0a0d11b0721","_cell_guid":"16c73f62-b0d8-43b7-8884-23cec46ab38c","trusted":true}},{"cell_type":"code","source":"# from sklearn.svm import SVR\n\n# svr = Pipeline([\n#     ('StandardScaler', StandardScaler()),\n#     ('SVR', SVR())\n# ])\n\n# svr.fit(X_train, y_train)\n# y_pred = svr.predict(X_test)\n\n# mae = MAE(y_test, y_pred)\n# mse = MSE(y_test, y_pred)\n# rmse = np.sqrt(mse)\n# r2 = R2(y_test, y_pred)\n\n# results.append([\"SVR\", mae, mse, rmse, r2])\n# print(results[-1])","metadata":{"_uuid":"3e4817d8-04f6-4697-a314-436a2f34b6e1","_cell_guid":"50e76523-cc9a-4965-a780-30c053a29885","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNeighbors Regressor","metadata":{"_uuid":"4a639921-31e1-4a3c-9aa9-b8128a280276","_cell_guid":"85309a5c-aabc-4bc6-8958-89200ce255f1","trusted":true}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nmaes = []\nmses = []\nrmses = []\nr2s = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):  \n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n\n    kNeighborsRegressor = Pipeline([\n        ('StandardScaler', StandardScaler()),\n        ('KNeighborsRegressor', KNeighborsRegressor())\n    ])\n\n    kNeighborsRegressor.fit(X_train, y_train)\n    y_pred = kNeighborsRegressor.predict(X_test)\n\n    maes.append(MAE(y_test, y_pred))\n    mses.append(MSE(y_test, y_pred))\n    rmses.append(np.sqrt(mses[-1]))\n    r2s.append(R2(y_test, y_pred))\n    \nresults.append([\"KNeighborsRegressor\", np.mean(maes), np.mean(mses), np.mean(rmses), np.mean(r2s)])\nprint(results[-1])","metadata":{"_uuid":"4f139e30-85e6-428d-87e3-56488bbfe997","_cell_guid":"ae72bc12-f90a-46f9-9450-8012dfa0a6c4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Result","metadata":{"_uuid":"bf859c69-e73d-4990-bdac-b0e659292d8c","_cell_guid":"7bef3825-6865-4954-b9c0-61a182382bf8","trusted":true}},{"cell_type":"code","source":"results = pd.DataFrame(results, columns = [\"Models\", \"MAE\", \"MSE\", \"RMSE\", \"R^2\"]).sort_values(\"R^2\", ascending = False).reset_index(drop = True)","metadata":{"_uuid":"eb1d84a1-4803-4259-b372-34e575e16aac","_cell_guid":"f0a208a6-14a0-45dc-a9d7-09b3c4d9aaf9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"_uuid":"9d1e5188-84e4-4efe-b799-aa65c6a3a429","_cell_guid":"9eb91ff6-1f44-429d-b7b0-588fe034ced5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.to_csv('results.csv')","metadata":{"_uuid":"da038aa2-0e10-45a9-a50a-3c5857697137","_cell_guid":"fa7e23c5-839b-4e72-8a4b-09863e8f9f20","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}